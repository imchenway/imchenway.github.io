<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="DavidChan,imchenway@gmail.com"><title>AI Gateway：把 LLM 调用升级为“可治理的网关层”（鉴权/限流/缓存/审计） · DavidChan's Blog</title><meta name="description" content="本文目录#




引言：为什么“直接调模型 SDK”会在规模化时失控
1. AI Gateway 的最小定义：统一契约 + 策略执行点 + 证据链
2. 统一“调用契约”：把模型调用变成可演进的 API
3. 治理能力拆解：AI Gateway 该“管什么”
3.1 身份与鉴权：谁能调、能调什么
"><link rel="canonical" href="https://imchenway.com/zh-CN/2026-01-ai-gateway-governance/"><link rel="alternate" hreflang="en" href="https://imchenway.com/en/ai-gateway-governance/"><link rel="alternate" hreflang="zh-CN" href="https://imchenway.com/zh-CN/2026-01-ai-gateway-governance/"><link rel="alternate" hreflang="x-default" href="https://imchenway.com/zh-CN/2026-01-ai-gateway-governance/"><meta property="og:type" content="article"><meta property="og:title" content="AI Gateway：把 LLM 调用升级为“可治理的网关层”（鉴权/限流/缓存/审计）"><meta property="og:description" content="本文目录# 引言：为什么“直接调模型 SDK”会在规模化时失控 1. AI Gateway 的最小定义：统一契约 + 策略执行点 + 证据链 2. 统一“调用契约”：把模型调用变成可演进的 API 3. 治理能力拆解：AI Gateway 该“管什么” 3.1 身份与鉴权：谁能调、能调什么 3.2 预算与限流：把 To"><meta property="og:url" content="https://imchenway.com/zh-CN/2026-01-ai-gateway-governance/"><meta property="og:site_name" content="DavidChan's Blog"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="AI Gateway：把 LLM 调用升级为“可治理的网关层”（鉴权/限流/缓存/审计）"><meta name="twitter:description" content="本文目录# 引言：为什么“直接调模型 SDK”会在规模化时失控 1. AI Gateway 的最小定义：统一契约 + 策略执行点 + 证据链 2. 统一“调用契约”：把模型调用变成可演进的 API 3. 治理能力拆解：AI Gateway 该“管什么” 3.1 身份与鉴权：谁能调、能调什么 3.2 预算与限流：把 To"><meta name="keywords" content="DavidChan,imchenway"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/typography-override.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><link rel="shortcut icon" type="image/png" href="/images/favicon.png"><script>var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.type = 'text/javascript';hm.async = true;
    hm.src = "https://hm.baidu.com/hm.js?542ea8c4a9ce535736e775029b1fad26";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
})();
</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PJKTXDR70K"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PJKTXDR70K');
</script><script async crossorigin="anonymous" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1946575658110055"></script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><h3 title=""><a href="/">DavidChan's Blog</a></h3><div class="description"><p>I hear and I forget. <br>I see and I remember. <br>I write and I understand.</p></div></div></div><ul class="social-links"><li><a href="/atom.xml"><i class="fa fa-rss"></i></a></li><li><a class="wechat-trigger" href="javascript:void(0);"><i class="fa fa-wechat"></i></a></li><h3 title=""></h3></ul><style>.wechat-modal {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: none;
  align-items: center;
  justify-content: center;
  background: rgba(0, 0, 0, 0.65);
  z-index: 2147483000;
}
.wechat-modal.is-active {
  display: flex;
}
.wechat-modal__content {
  position: relative;
  background: #fff;
  padding: 20px;
  border-radius: 6px;
  box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
  max-width: 90vw;
  max-height: 90vh;
  z-index: 2147483001;
}
.wechat-modal__image {
  max-width: 70vw;
  max-height: 70vh;
  display: block;
}
.wechat-modal__close {
  position: absolute;
  top: -12px;
  right: -12px;
  width: 28px;
  height: 28px;
  line-height: 28px;
  text-align: center;
  border-radius: 50%;
  background: #fff;
  color: #333;
  font-size: 20px;
  cursor: pointer;
  box-shadow: 0 2px 6px rgba(0, 0, 0, 0.15);
}
</style><div class="wechat-modal" id="wechat-modal" style="display:none;"><div class="wechat-modal__content"><span class="wechat-modal__close">&times;</span><img class="wechat-modal__image" src="https://imchenway.com/images/logo.png" data-original="https://hypha-mall.oss-cn-hangzhou.aliyuncs.com/imchenway-wechat.jpg" alt="WeChat QR code"></div></div><script>document.addEventListener('DOMContentLoaded', function () {
  var trigger = document.querySelector('.wechat-trigger');
  var modal = document.getElementById('wechat-modal');
  if (!trigger || !modal) return;
  if (modal.parentNode !== document.body) {
    document.body.appendChild(modal);
  }
  var closeBtn = modal.querySelector('.wechat-modal__close');
  var show = function () {
    modal.style.display = 'flex';
    modal.classList.add('is-active');
  };
  var hide = function () {
    modal.classList.remove('is-active');
    modal.style.display = 'none';
  };
  hide();
  trigger.addEventListener('click', function (event) {
    event.preventDefault();
    show();
  });
  closeBtn && closeBtn.addEventListener('click', hide);
  modal.addEventListener('click', function (event) {
    if (event.target === modal) hide();
  });
});</script></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><!--li--><!--  if is_current('about')--><!--    a.current(href="/about")= __('About')--><!--  else--><!--    a(href="/about")= __('About')--><li><a href="/guestbook">留言板</a></li></div><div class="information"><a class="lang-toggle" href="/en/ai-gateway-governance/">EN</a><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>AI Gateway：把 LLM 调用升级为“可治理的网关层”（鉴权/限流/缓存/审计）</a></h3></div><div class="post-content"><h3><span id="ben-wen-mu-lu">本文目录</span><a href="#ben-wen-mu-lu" class="header-anchor">#</a></h3><div class="toc">

<!-- toc -->

<ul>
<li><a href="#yin-yan-wei-shi-me-zhi-jie-diao-mo-xing-sdk-hui-zai-gui-mo-hua-shi-shi-kong">引言：为什么“直接调模型 SDK”会在规模化时失控</a></li>
<li><a href="#1-ai-gateway-de-zui-xiao-ding-yi-tong-yi-qi-yue-ce-lue-zhi-xing-dian-zheng-ju-lian">1. AI Gateway 的最小定义：统一契约 + 策略执行点 + 证据链</a></li>
<li><a href="#2-tong-yi-diao-yong-qi-yue-ba-mo-xing-diao-yong-bian-cheng-ke-yan-jin-de-api">2. 统一“调用契约”：把模型调用变成可演进的 API</a></li>
<li><a href="#3-zhi-li-neng-li-chai-jie-ai-gateway-gai-guan-shi-me">3. 治理能力拆解：AI Gateway 该“管什么”</a><ul>
<li><a href="#3-1-shen-fen-yu-jian-quan-shui-neng-diao-neng-diao-shi-me">3.1 身份与鉴权：谁能调、能调什么</a></li>
<li><a href="#3-2-yu-suan-yu-xian-liu-ba-token-cost-bian-cheng-yi-deng-gong-min">3.2 预算与限流：把 Token&#x2F;Cost 变成一等公民</a></li>
<li><a href="#3-3-lu-you-yu-jiang-ji-duo-mo-xing-duo-qu-yu-yu-gu-zhang-qie-huan">3.3 路由与降级：多模型、多区域与故障切换</a></li>
<li><a href="#3-4-huan-cun-prompt-caching-vs-yu-yi-huan-cun">3.4 缓存：Prompt Caching vs 语义缓存</a></li>
<li><a href="#3-5-ke-kao-xing-chao-shi-chong-shi-rong-duan-mi-deng">3.5 可靠性：超时、重试、熔断、幂等</a></li>
<li><a href="#3-6-an-quan-yu-he-gui-tuo-min-shen-ji-zhu-ru-fang-xian">3.6 安全与合规：脱敏、审计、注入防线</a></li>
</ul>
</li>
<li><a href="#4-ke-guan-ce-xing-rang-yi-ci-mo-xing-diao-yong-bian-cheng-ke-hui-fang-de-span">4. 可观测性：让一次模型调用变成“可回放的 Span”</a></li>
<li><a href="#5-bu-shu-xing-tai-yu-xuan-xing-zhong-yang-wang-guan-vs-sidecar">5. 部署形态与选型：中央网关 vs Sidecar</a><ul>
<li><a href="#5-1-zhong-yang-wang-guan-central-gateway">5.1 中央网关（Central Gateway）</a></li>
<li><a href="#5-2-sidecar-ben-di-dai-li-per-service-proxy">5.2 Sidecar&#x2F;本地代理（Per-service Proxy）</a></li>
</ul>
</li>
<li><a href="#6-jian-jin-shi-luo-di-lu-xian-cong-pang-lu-guan-ce-dao-qiang-zhi-zhi-li">6. 渐进式落地路线：从旁路观测到强制治理</a></li>
<li><a href="#7-yi-ge-tuo-min-an-li-ba-cheng-ben-shi-kong-quan-xian-hun-luan-shou-lian-dao-ke-yun-ying">7. 一个脱敏案例：把“成本失控 + 权限混乱”收敛到可运营</a></li>
<li><a href="#jie-yu-ba-ai-dang-zuo-ping-tai-neng-li-er-bu-shi-san-luo-de-sdk">结语：把 AI 当作平台能力，而不是散落的 SDK</a></li>
<li><a href="#can-kao-zi-liao">参考资料</a></li>
</ul>
<!-- tocstop -->

</div>

<h1><span id="yin-yan-wei-shi-me-zhi-jie-diao-mo-xing-sdk-hui-zai-gui-mo-hua-shi-shi-kong">引言：为什么“直接调模型 SDK”会在规模化时失控</span><a href="#yin-yan-wei-shi-me-zhi-jie-diao-mo-xing-sdk-hui-zai-gui-mo-hua-shi-shi-kong" class="header-anchor">#</a></h1><p>很多团队做生成式能力落地，第一步几乎都是“业务服务直接调模型 SDK”。这条路径能快速上线，但一旦从「单个团队试点」走到「多团队、多产品、多模型、多租户」，你会发现问题开始以一种非常工程化的方式堆积：</p>
<ul>
<li><strong>密钥与鉴权四散</strong>：每个服务各自持有 Provider Key，权限边界变得模糊；一旦要做最小权限、密钥轮换、审计追责，链路很难统一。</li>
<li><strong>成本与配额不可控</strong>：同样是一次请求，有的团队开了长上下文、有的加了多轮重试、有的无缓存；成本像“隐形税”一样累积，直到某天账单爆炸。</li>
<li><strong>可观测性缺失</strong>：你能看到最终输出，但不知道中间用了哪个模型、走了几次重试、命中了没有缓存、触发了哪些安全&#x2F;过滤规则，更无法回放与复盘。</li>
<li><strong>可靠性被供应商抖动放大</strong>：某个模型偶发超时、某个区域抖动、某个限流阈值变更，会直接把故障扩散到业务层。</li>
<li><strong>合规与安全变成“事后补丁”</strong>：PII 脱敏、数据驻留、日志留存、提示注入（prompt injection）与越权工具调用等风险，如果不在“统一入口”解决，后面会非常痛苦。[4][5]</li>
</ul>
<p>这时你真正需要的，不是再写一套 SDK 封装，而是把 LLM 调用从“散落的代码片段”升级为<strong>平台级能力</strong>：像治理 API 一样治理模型调用。这个平台入口，就是本文要讲的 <strong>AI Gateway</strong>。</p>
<h1><span id="1-ai-gateway-de-zui-xiao-ding-yi-tong-yi-qi-yue-ce-lue-zhi-xing-dian-zheng-ju-lian">1. AI Gateway 的最小定义：统一契约 + 策略执行点 + 证据链</span><a href="#1-ai-gateway-de-zui-xiao-ding-yi-tong-yi-qi-yue-ce-lue-zhi-xing-dian-zheng-ju-lian" class="header-anchor">#</a></h1><p>我对 AI Gateway 的“最小定义”是三句话：</p>
<ol>
<li><strong>统一契约（Contract）</strong>：把各家模型&#x2F;供应商的请求形态收敛成一套你能演进的请求&#x2F;响应协议（包含元数据、幂等、错误码、版本等）。  </li>
<li><strong>统一策略执行点（Policy Enforcement Point）</strong>：把鉴权、限流、预算、路由、缓存、重试、脱敏、审计等治理能力集中在一个入口执行，而不是散落在每个业务服务里。  </li>
<li><strong>统一证据链（Observability &amp; Audit Trail）</strong>：让每次调用可追踪、可度量、可回放：谁调用了什么、花了多少钱、触发了哪些规则、是否越权、出了问题怎么定位。</li>
</ol>
<p>你可以把它类比为“API Gateway + Service Mesh + FinOps + 审计”的组合，但对象从 HTTP API 变成了 LLM（以及 Agent 的工具调用链）。</p>
<p>一个典型调用链可以画成这样：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Client / Service / Agent</span><br><span class="line">        |</span><br><span class="line">        |  (统一请求契约 + 业务元数据：tenant/user/use_case/trace_id)</span><br><span class="line">        v</span><br><span class="line">     AI Gateway  ----------------------+</span><br><span class="line">        |                              |</span><br><span class="line">        | (鉴权/配额/预算/限流/脱敏)     | (可观测：trace/metrics/logs)</span><br><span class="line">        | (路由/灰度/降级/缓存)          |</span><br><span class="line">        v                              v</span><br><span class="line">  LLM Providers / Model APIs       Observability &amp; Audit Storage</span><br></pre></td></tr></table></figure>

<h1><span id="2-tong-yi-diao-yong-qi-yue-ba-mo-xing-diao-yong-bian-cheng-ke-yan-jin-de-api">2. 统一“调用契约”：把模型调用变成可演进的 API</span><a href="#2-tong-yi-diao-yong-qi-yue-ba-mo-xing-diao-yong-bian-cheng-ke-yan-jin-de-api" class="header-anchor">#</a></h1><p>如果你没有统一契约，治理会很快碎片化：每个团队会在自己的 wrapper 里定义不同的字段、不同的错误处理、不同的重试策略。久而久之，“平台治理”无法落地，因为你连“在一个地方做策略”都做不到。</p>
<p>一个实用的契约至少要包含这些要素（不等于具体实现，只是对外的“口径”）：</p>
<ul>
<li><strong>身份与场景元数据</strong>：<code>tenant_id / user_id / channel / use_case / data_classification</code>  </li>
<li><strong>请求可关联</strong>：<code>trace_id / span_id / request_id</code>（便于端到端追踪）[3]  </li>
<li><strong>幂等与重试安全</strong>：<code>idempotency_key</code>（避免重试导致重复扣费&#x2F;重复执行工具）  </li>
<li><strong>预算约束</strong>：<code>max_tokens / max_cost / max_latency_ms</code>（把预算变成一等公民）  </li>
<li><strong>模型选择语义</strong>：<code>model_family / quality_tier / region_preference</code>（而不是写死某个具体模型名）  </li>
<li><strong>安全与合规模块</strong>：<code>redaction_profile / retention_policy / pii_mode</code>  </li>
<li><strong>错误码规范化</strong>：把各供应商的错误统一成你自己的错误分类（超时、限流、无权限、内容违规、上游故障等）</li>
</ul>
<p>这件事的关键不是“字段越多越好”，而是你要能做到两点：</p>
<ul>
<li><strong>业务能稳定调用</strong>：不因换模型&#x2F;换供应商而大改代码。  </li>
<li><strong>平台能稳定演进</strong>：契约版本化，向后兼容，有灰度与回滚路径。</li>
</ul>
<h1><span id="3-zhi-li-neng-li-chai-jie-ai-gateway-gai-guan-shi-me">3. 治理能力拆解：AI Gateway 该“管什么”</span><a href="#3-zhi-li-neng-li-chai-jie-ai-gateway-gai-guan-shi-me" class="header-anchor">#</a></h1><p>下面我按“治理目标”把能力拆成 6 组，你可以用它做需求清单，也可以当作架构评审 checklist。</p>
<h2><span id="3-1-shen-fen-yu-jian-quan-shui-neng-diao-neng-diao-shi-me">3.1 身份与鉴权：谁能调、能调什么</span><a href="#3-1-shen-fen-yu-jian-quan-shui-neng-diao-neng-diao-shi-me" class="header-anchor">#</a></h2><p>传统 API 里，鉴权常见是 API Key &#x2F; OAuth &#x2F; mTLS。到了 LLM 场景，你还需要更细的策略维度：</p>
<ul>
<li><strong>按租户&#x2F;团队&#x2F;应用隔离</strong>：不同租户走不同的 key&#x2F;结算&#x2F;数据驻留策略。</li>
<li><strong>按用例分级</strong>：同一应用里，“客服回复”与“财务总结”可能需要不同的模型白名单与输出约束。</li>
<li><strong>最小权限</strong>：不是“给所有服务一个万能 Key”，而是把调用能力收敛成最小集合（能用哪些模型、能否使用工具、最大上下文与预算上限）。[5]</li>
</ul>
<p>落地时，常见做法是在网关统一做身份解析与策略匹配：<code>(tenant, app, use_case) -&gt; policy</code>。</p>
<h2><span id="3-2-yu-suan-yu-xian-liu-ba-token-x2f-cost-bian-cheng-yi-deng-gong-min">3.2 预算与限流：把 Token&#x2F;Cost 变成一等公民</span><a href="#3-2-yu-suan-yu-xian-liu-ba-token-x2f-cost-bian-cheng-yi-deng-gong-min" class="header-anchor">#</a></h2><p>LLM 的“成本”不像传统 API 那样稳定：prompt 长度、输出长度、重试次数、工具调用、检索结果注入都会影响 token 与费用。</p>
<p>AI Gateway 应该提供三种层级的预算控制：</p>
<ol>
<li><strong>实时限流（Rate Limit）</strong>：按租户&#x2F;应用&#x2F;用例限制 QPS，并区分“生成&#x2F;嵌入&#x2F;图像”等不同操作。  </li>
<li><strong>预算闸门（Budget Gate）</strong>：按天&#x2F;周&#x2F;月设定 token 或金额预算，到阈值自动降级&#x2F;拒绝&#x2F;切换低成本模型。  </li>
<li><strong>单请求预算（Per-request Budget）</strong>：对单次调用设置 <code>max_tokens / max_cost / max_latency_ms</code>，超出直接中断或降级。</li>
</ol>
<p>这样做的好处是：成本治理不再是“月底对账”，而是能在分钟级甚至秒级生效。</p>
<h2><span id="3-3-lu-you-yu-jiang-ji-duo-mo-xing-duo-qu-yu-yu-gu-zhang-qie-huan">3.3 路由与降级：多模型、多区域与故障切换</span><a href="#3-3-lu-you-yu-jiang-ji-duo-mo-xing-duo-qu-yu-yu-gu-zhang-qie-huan" class="header-anchor">#</a></h2><p>当你接入多个模型（或同一模型的多区域&#x2F;多供应商），路由与降级会变成日常：</p>
<ul>
<li><strong>按质量层级路由</strong>：同一用例可以声明 <code>quality_tier=high/standard/cheap</code>，网关再映射到具体模型与参数。</li>
<li><strong>按区域与数据驻留路由</strong>：欧盟用户走 EU 区域；敏感数据走私有部署；这类策略应当是网关层的一部分。</li>
<li><strong>按健康度故障切换</strong>：上游超时&#x2F;限流时，自动切到备用模型或返回“可接受的降级答案”。</li>
</ul>
<p>更进一步，网关还可以承载<strong>灰度与 A&#x2F;B</strong>：让新模型只吃 1% 流量，观察成本&#x2F;延迟&#x2F;正确性指标，再逐步扩大。</p>
<h2><span id="3-4-huan-cun-prompt-caching-vs-yu-yi-huan-cun">3.4 缓存：Prompt Caching vs 语义缓存</span><a href="#3-4-huan-cun-prompt-caching-vs-yu-yi-huan-cun" class="header-anchor">#</a></h2><p>缓存是把成本打下来的“硬手段”，但也是最容易踩安全坑的地方。两类缓存常见：</p>
<ul>
<li><strong>Prompt Caching（精确缓存）</strong>：请求完全相同（或规范化后相同）就复用结果。适合模板化、重复率高、可接受一致性的场景。</li>
<li><strong>语义缓存（Semantic Cache）</strong>：近似请求命中近似答案，节省生成开销。适合 FAQ、知识类问答，但对“事实准确&#x2F;最新”要求高的场景要谨慎。</li>
</ul>
<p>网关层做缓存有两个优势：</p>
<ol>
<li><strong>统一命中口径</strong>：不然每个团队自己缓存，会出现“命中率统计不可比”。  </li>
<li><strong>统一安全策略</strong>：缓存是否可存、存多久、是否按租户隔离、是否需要加密，必须由同一处治理。</li>
</ol>
<p>务必注意：缓存与日志一样，是合规与隐私的高风险点。你需要明确保留策略与脱敏规则。[5]</p>
<h2><span id="3-5-ke-kao-xing-chao-shi-chong-shi-rong-duan-mi-deng">3.5 可靠性：超时、重试、熔断、幂等</span><a href="#3-5-ke-kao-xing-chao-shi-chong-shi-rong-duan-mi-deng" class="header-anchor">#</a></h2><p>LLM 调用的失败模式通常比普通 HTTP 更复杂：上游限流、排队、长尾延迟、流式中断、响应被过滤等。网关需要把这些能力“产品化”：</p>
<ul>
<li><strong>超时策略</strong>：不同用例设置不同 <code>timeout</code>；“交互式”优先低延迟，“离线总结”可以容忍更久。</li>
<li><strong>重试与退避</strong>：对可重试错误（如 429、5xx）做指数退避；对不可重试错误（如鉴权失败、内容违规）快速失败。</li>
<li><strong>熔断与隔离</strong>：当某个模型持续失败时，快速切走，避免雪崩。</li>
<li><strong>幂等</strong>：尤其在 agent 工具调用链里，如果你把“模型输出”进一步驱动“外部动作”，幂等与审计会直接影响事故概率。</li>
</ul>
<p>这类机制并不新，Envoy 等代理体系已把它们做成成熟能力；AI Gateway 要做的是把这些能力“贴合到 LLM 语义”上。[2]</p>
<h2><span id="3-6-an-quan-yu-he-gui-tuo-min-shen-ji-zhu-ru-fang-xian">3.6 安全与合规：脱敏、审计、注入防线</span><a href="#3-6-an-quan-yu-he-gui-tuo-min-shen-ji-zhu-ru-fang-xian" class="header-anchor">#</a></h2><p>当 LLM 走进生产，安全不再只是“输出有没有违规”，而是更广义的风险面：</p>
<ul>
<li><strong>数据外泄</strong>：PII&#x2F;机密数据进入 prompt、进入日志、进入缓存，或者通过引用&#x2F;工具调用被带出边界。</li>
<li><strong>提示注入与数据投毒</strong>：检索到的内容（网页&#x2F;文档&#x2F;工单）本身可能携带恶意指令，诱导模型越权调用工具或泄露信息。[4]</li>
<li><strong>合规留痕</strong>：当出现争议输出或越权操作，你需要能回答：谁触发的？用的什么数据？走了哪些策略？</li>
</ul>
<p>AI Gateway 常见的做法是把安全能力分成三段：</p>
<ol>
<li><strong>入口净化与分级</strong>：按数据分级决定是否允许出边界、是否必须脱敏。  </li>
<li><strong>策略约束与白名单</strong>：允许哪些模型、哪些工具、哪些来源；对高风险动作引入审批&#x2F;双人复核（视组织而定）。  </li>
<li><strong>审计与回放</strong>：将策略决策与关键元数据写入审计存储，形成可追责证据链。[4][5]</li>
</ol>
<h1><span id="4-ke-guan-ce-xing-rang-yi-ci-mo-xing-diao-yong-bian-cheng-ke-hui-fang-de-span">4. 可观测性：让一次模型调用变成“可回放的 Span”</span><a href="#4-ke-guan-ce-xing-rang-yi-ci-mo-xing-diao-yong-bian-cheng-ke-hui-fang-de-span" class="header-anchor">#</a></h1><p>如果你已经写过分布式系统，你会知道：当系统复杂度上来，“可观测性不是锦上添花，而是生存条件”。AI Gateway 的价值之一，是把 LLM 调用天然变成一个可观测节点：</p>
<ul>
<li><strong>Tracing</strong>：每次调用是一个 span，至少包含 <code>model/provider/tenant/use_case</code> 等维度，并能关联到上游业务 trace。[3]  </li>
<li><strong>Metrics</strong>：请求量、成功率、p95&#x2F;p99 延迟、token 使用、成本估算、缓存命中率、重试次数、限流次数、过滤触发次数等。  </li>
<li><strong>Logs</strong>：结构化日志记录元数据与策略决策（注意脱敏与保留策略）。</li>
</ul>
<p>你最终要达到的效果不是“有一堆日志”，而是能回答这些问题：</p>
<ul>
<li>成本上升来自哪个租户&#x2F;用例？是 prompt 变长还是重试变多？  </li>
<li>延迟变差是模型变慢、上游排队，还是网关侧缓存失效？  </li>
<li>安全事件触发时，是否能回放当时的决策链？能否验证策略是否生效？</li>
</ul>
<p>这类观测体系最好直接对齐 OpenTelemetry 语义与采集链路，避免自建孤岛。[3]</p>
<h1><span id="5-bu-shu-xing-tai-yu-xuan-xing-zhong-yang-wang-guan-vs-sidecar">5. 部署形态与选型：中央网关 vs Sidecar</span><a href="#5-bu-shu-xing-tai-yu-xuan-xing-zhong-yang-wang-guan-vs-sidecar" class="header-anchor">#</a></h1><p>AI Gateway 并不只有一种形态，常见两类：</p>
<h2><span id="5-1-zhong-yang-wang-guan-central-gateway">5.1 中央网关（Central Gateway）</span><a href="#5-1-zhong-yang-wang-guan-central-gateway" class="header-anchor">#</a></h2><p><strong>优点</strong>：策略集中、统一审计、统一缓存与路由、成本看板口径一致。<br><strong>缺点</strong>：成为关键路径，需要高可用与容量规划；跨区域场景要考虑就近接入与数据驻留。</p>
<h2><span id="5-2-sidecar-x2f-ben-di-dai-li-per-service-proxy">5.2 Sidecar&#x2F;本地代理（Per-service Proxy）</span><a href="#5-2-sidecar-x2f-ben-di-dai-li-per-service-proxy" class="header-anchor">#</a></h2><p><strong>优点</strong>：就近处理、降低跨网延迟、与服务网格天然融合；局部故障影响面小。<br><strong>缺点</strong>：策略与版本治理更复杂；统一缓存与统一审计更难做。</p>
<p>如果你在 Kubernetes 上，Gateway API 是一个值得关注的抽象：它让“网关能力”从具体实现（Ingress Controller）中抽离出来，用统一 CRD 描述路由与策略，再由实现（例如 Envoy）承载数据面。[1][2]</p>
<h1><span id="6-jian-jin-shi-luo-di-lu-xian-cong-pang-lu-guan-ce-dao-qiang-zhi-zhi-li">6. 渐进式落地路线：从旁路观测到强制治理</span><a href="#6-jian-jin-shi-luo-di-lu-xian-cong-pang-lu-guan-ce-dao-qiang-zhi-zhi-li" class="header-anchor">#</a></h1><p>如果你已经有一堆业务在直连模型，直接“切网关”往往风险很高。我更推荐 4 个阶段的渐进路线：</p>
<ol>
<li><strong>旁路观测（Shadow）</strong>：先让流量镜像&#x2F;旁路到网关，只做打点与审计，不影响线上响应。  </li>
<li><strong>统一契约（Contract First）</strong>：在不改变业务功能的前提下，让业务逐步改成调用统一网关 API。  </li>
<li><strong>温和治理（Soft Enforcement）</strong>：先上限流&#x2F;超时&#x2F;重试&#x2F;基本脱敏，策略命中但不强制拦截（只告警）。  </li>
<li><strong>强制治理（Hard Gates）</strong>：对高风险用例启用预算闸门、模型白名单、缓存策略与审计留存要求。</li>
</ol>
<p>这条路线的核心是：<strong>先建立证据链，再谈红线</strong>。没有可观测与审计，任何治理都会变成拍脑袋。</p>
<h1><span id="7-yi-ge-tuo-min-an-li-ba-cheng-ben-shi-kong-quan-xian-hun-luan-shou-lian-dao-ke-yun-ying">7. 一个脱敏案例：把“成本失控 + 权限混乱”收敛到可运营</span><a href="#7-yi-ge-tuo-min-an-li-ba-cheng-ben-shi-kong-quan-xian-hun-luan-shou-lian-dao-ke-yun-ying" class="header-anchor">#</a></h1><p>一个很典型的场景（已脱敏）：</p>
<ul>
<li>三个团队各自接了两个供应商模型，Key 分散在各自服务的环境变量里；</li>
<li>某次活动期间，客服机器人突然变“健谈”，token 消耗翻倍；同时因为上游偶发限流，业务代码做了三次重试，进一步放大成本；</li>
<li>事后复盘时，团队只能看到“某些接口变慢了”，却无法还原：到底是哪个租户、哪个用例、哪种 prompt 变长、哪次重试导致；</li>
</ul>
<p>引入 AI Gateway 后，团队先做了两件“小而硬”的事：</p>
<ol>
<li><strong>把调用契约统一</strong>：所有调用都必须带 <code>tenant/use_case/trace_id</code>，并写入统一审计。  </li>
<li><strong>把预算写进策略</strong>：对活动期的用例设置单请求 <code>max_tokens</code> 与租户级预算阈值，超限自动降级到更便宜的模型或返回短回复模板。</li>
</ol>
<p>有了这两点，后续再逐步叠加缓存、路由与更细的权限策略，就进入了“可运营”的轨道：成本、延迟与风险不再是黑箱，而是可以被度量与治理的对象。</p>
<h1><span id="jie-yu-ba-ai-dang-zuo-ping-tai-neng-li-er-bu-shi-san-luo-de-sdk">结语：把 AI 当作平台能力，而不是散落的 SDK</span><a href="#jie-yu-ba-ai-dang-zuo-ping-tai-neng-li-er-bu-shi-san-luo-de-sdk" class="header-anchor">#</a></h1><p>AI Gateway 的本质不是“再加一层代理”，而是把模型调用这件事，按平台工程的方法论重新做一遍：契约、策略、观测、审计、灰度、回滚。</p>
<p>如果你的团队正在经历以下任一信号：</p>
<ul>
<li>多团队接入、多模型并存、需求快速膨胀；</li>
<li>成本开始不可控，或你无法解释成本变化；</li>
<li>合规、安全、审计要求逐步变严；</li>
<li>线上偶发问题难复现、难定位；</li>
</ul>
<p>那么你大概率已经到了“需要 AI Gateway”的阶段。它不会让模型更聪明，但会让你的系统更可控、更可靠，也更能承受规模化。</p>
<h1><span id="can-kao-zi-liao">参考资料</span><a href="#can-kao-zi-liao" class="header-anchor">#</a></h1><ul>
<li>[1] Kubernetes SIGs, Gateway API Documentation, <a target="_blank" rel="noopener" href="https://gateway-api.sigs.k8s.io/">https://gateway-api.sigs.k8s.io/</a></li>
<li>[2] Envoy Proxy Documentation, <a target="_blank" rel="noopener" href="https://www.envoyproxy.io/docs/envoy/latest/">https://www.envoyproxy.io/docs/envoy/latest/</a></li>
<li>[3] OpenTelemetry Documentation, <a target="_blank" rel="noopener" href="https://opentelemetry.io/docs/">https://opentelemetry.io/docs/</a></li>
<li>[4] OWASP Top 10 for Large Language Model Applications, <a target="_blank" rel="noopener" href="https://owasp.org/www-project-top-10-for-large-language-model-applications/">https://owasp.org/www-project-top-10-for-large-language-model-applications/</a></li>
<li>[5] NIST AI Risk Management Framework (AI RMF), <a target="_blank" rel="noopener" href="https://www.nist.gov/itl/ai-risk-management-framework">https://www.nist.gov/itl/ai-risk-management-framework</a></li>
</ul>
<hr>
<p>本作品系原创，采用<a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.≠0/deed.zh">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可，转载请注明出处。</p>

<div id="gitalk-container"></div>
<script src="https://cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

		<script>
		var gitalkConfig = {"enable":true,"owner":"imchenway","repo":"imchenway.github.io","admin":"imchenway","clientID":"7026ab2c4cdadba4d342","clientSecret":"8e00dadc2db335285be4c861e53ee1bf9f8cc713","distractionFreeMode":false,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"};
	    gitalkConfig.id = md5(location.pathname);
		var gitalk = new Gitalk(gitalkConfig);
	    gitalk.render("gitalk-container");
	    </script></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2026-01-29</span></div></div></div></div><div class="post-ad"><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1946575658110055" data-ad-slot="8561874775"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/en/ai-gateway-governance/" title="AI Gateway: Building a Governed Gateway Layer for LLM Calls (Auth, Rate Limits, Caching, Audit)">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/en/rag-2-0-governable-rag/" title="RAG 2.0: From Vectors to Structured Knowledge, Graphs, and Permission-Aware Retrieval">下一篇</a></li></ul></div></div></div></div></div><script defer src="/js/jquery.js"></script><script defer src="/js/jquery-migrate-1.2.1.min.js"></script><script defer src="/js/jquery.appear.js"></script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body></html>