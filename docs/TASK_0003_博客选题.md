# /TASK_0003 博客选题（选题阶段）

日期：2026-01-21  
状态：写作阶段已完成（2026-01-29：AI Gateway 中英已落盘；当前回到选题阶段）

## 1. 背景与现状扫描（基于仓库）
- 内容形态：Hexo 博客，文章主要在 `source/_posts/`，支持中英双语（如 `*-en.md`）。
- 近期 AI 主题：  
  - Vibe Coding 代理对比：`source/_posts/2025-09-vibe-coding-agents.md`  
  - AI 性能预算/FinOps：`source/_posts/2025-10-ai-performance-budget.md`  
  - LLM 推理微服务：`source/_posts/2025-10-llm-inference-microservices.md`  
  - 独立开发者 GPT+Agent：`source/_posts/2025-10-gpt-agent-indie.md`
- 标签风格：`tags: ['#AI', '#Tools', '#VIBE']`（带 `#` 的短标签）。

## 2. 选题产出（候选 8 个）

### 2.1 选题 1：MCP：让 AI Agent 像插件系统一样接入企业工具
- English: **MCP in Practice: A Plug-in Protocol for Real-World Agents**
- 价值：把“工具接入”从一次性胶水代码升级为可治理的协议层；适合衔接你已有的工具链/工程化主题，并自然延伸到权限、审计与生态建设。
- 提纲：
  1) 为什么需要统一的工具协议（从 tool calling 到工具生态）  
  2) MCP 的最小可用架构：Server/Client/Transport  
  3) 权限与审计：最小权限、密钥托管、可回放  
  4) 工程落地：工具目录、版本治理与灰度升级
- 标签：`['#MCP', '#Agents', '#Tools', '#Security', '#Architecture']`

### 2.2 选题 2：Agent Evals：把提示词与工具调用纳入 CI 的回归测试
- English: **Agent Evals: Regression Testing for Prompts, Tools, and Workflows**
- 价值：解决“改了 Prompt/策略但线上悄悄变坏”的典型痛点；与现有的可观测、质量闸门、性能预算文章形成闭环。
- 提纲：
  1) Eval 三层：单步 / 工作流 / 端到端  
  2) 用例来源：线上 Trace 回放、合成数据与人工标注  
  3) 指标体系：正确性、稳定性、成本、延迟、拒答率  
  4) CI 落地：红线闸门、灰度发布与自动回滚
- 标签：`['#AI', '#Testing', '#Observability', '#Automation', '#SLO']`

### 2.3 选题 3：多模型路由与推理 FinOps：Router + Cache + 灰度
- English: **Multi-Model Routing & LLM FinOps: Router, Cache, and Rollouts**
- 价值：把“质量/成本/延迟”当作三角约束，给出可落地的路由、缓存、降级和发布策略；可作为你 AI 性能预算系列的续篇。
- 提纲：
  1) 路由策略：规则/Embedding/Router Model/分层升级  
  2) 缓存策略：Prompt Caching vs 语义缓存（命中率与一致性）  
  3) 预算联动：成本上限、延迟 SLO 与自动降级  
  4) 灰度发布：按客群/风险/地域分流与回滚
- 标签：`['#CostOptimization', '#FinOps', '#AIInfrastructure', '#Architecture', '#Performance']`

### 2.4 选题 4：Agent 安全基线：从 Prompt Injection 到 Tool Abuse 的防线
- English: **Securing Agents: From Prompt Injection to Tool Abuse**
- 价值：把“Agent 接工具 = 新攻击面”讲清楚，并给出能抄作业的安全基线与 Checklist；适合结合你已有的工程实践/治理风格。
- 提纲：
  1) 威胁模型：提示注入、越权调用、数据外泄、供应链风险  
  2) 防护分层：输入净化、策略引擎、工具权限、沙箱隔离  
  3) 审计与追责：日志、Trace、回放与变更审计  
  4) 组织流程：安全评审 Checklist + 红队演练
- 标签：`['#Security', '#AI', '#Agents', '#Checklist', '#Practice']`

### 2.5 选题 5：Agent 可观测性（AgentOps）：把 Prompt/Tool/Memory 变成可追踪的 Span
- English: **Agent Observability: Turning Prompts, Tools, and Memory into Traces**
- 价值：给出可直接迁移到生产的观测模型：指标、追踪、日志、告警、复盘模板；与站内 Observability 主题天然契合。
- 提纲：
  1) 观测对象：Prompt、Tool Call、Retrieval、Memory、Guardrail  
  2) 追踪模型：把一次 Agent 任务拆成可关联的 Span/Trace  
  3) 质量闸门：错误预算、失败模式与自动降级  
  4) 运营视角：看板、告警阈值与复盘模板
- 标签：`['#Observability', '#OpenTelemetry', '#AIInfrastructure', '#SRE', '#Tracing']`

### 2.6 选题 6：RAG 2.0：从向量检索到“结构化知识 + 图谱 + 权限”
- English: **RAG 2.0: Beyond Vectors—Structured Data, Graphs, and Permissions**
- 价值：把 RAG 从“堆向量库”升级为可治理的数据系统：新鲜度、权限、多租户、引用可追溯；可与站内数据库/CDC/检索性能主题串联。
- 提纲：
  1) 混合检索：BM25 + Vector + SQL（以及何时引入图）  
  2) 数据新鲜度：CDC/增量索引/回滚与一致性  
  3) 权限与多租户：行级权限、过滤与审计  
  4) 可信回答：引用、置信度、拒答与可追溯
- 标签：`['#RAG', '#Database', '#Search', '#MultiTenant', '#AI']`

### 2.7 选题 7：边缘推理与私有化：什么时候该把模型搬到离用户更近的地方
- English: **Edge & On-Prem Inference: When the Model Should Move Closer**
- 价值：把“边缘/本地推理”从概念落到决策矩阵与运维方案：延迟、隐私、成本、可用性；承接你已有的 Serverless/Edge 主题。
- 提纲：
  1) 决策矩阵：延迟/隐私/成本/合规/可用性  
  2) 分层架构：云-边-端路由与缓存  
  3) 运维治理：版本、灰度、回滚、可观测  
  4) 典型场景：客服/搜索/个性化的边缘落地
- 标签：`['#EdgeComputing', '#Serverless', '#Performance', '#Security', '#AIInfrastructure']`

### 2.8 选题 8：AI 时代的工程文化：代码由谁负责？把 Agent 纳入 Review、发布与复盘
- English: **Engineering Culture in the AI Era: Ownership, Reviews, and Postmortems with Agents**
- 价值：讨论“代理写的代码怎么负责”的组织问题：责任边界、评审口径、发布闸门、复盘记录；适合作为系列收束与方法论总结。
- 提纲：
  1) 责任边界：作者/审阅者/代理的角色与授权  
  2) Review 机制：最小变更、可解释性与证据链  
  3) 发布闸门：测试、回滚、变更审计与合规  
  4) 复盘：如何记录 Agent 决策、上下文与教训
- 标签：`['#Practice', '#Postmortem', '#CI/CD', '#VIBE', '#Automation']`

## 3. 可验证资料（官方/权威入口）
```text
# OpenAI（官方 GitHub）
https://github.com/openai/openai-openapi
https://github.com/openai/openai-python

# Anthropic（官方文档）& MCP（官方站点）
https://docs.anthropic.com/
https://modelcontextprotocol.io/

# LangGraph（官方）
https://langchain-ai.github.io/langgraph/
https://github.com/langchain-ai/langgraph

# OpenTelemetry（官方）
https://opentelemetry.io/docs/

# OWASP LLM Top 10（权威安全基线）
https://owasp.org/www-project-top-10-for-large-language-model-applications/

# NIST AI RMF（权威风险治理框架）
https://www.nist.gov/itl/ai-risk-management-framework
```

## 4. 待决策项（写作阶段入口）
1) 本轮优先进入写作阶段的主选题（从影响力与站内延续性角度推荐）：  
   A. 选题 5（Agent 可观测性 / AgentOps）*推荐*  
   B. 选题 2（Agent Evals / 回归测试）  
   C. 选题 1（MCP 工具协议落地）  
   D. 选题 4（Agent 安全基线）

2) 内容形式偏好：  
   A. 单篇深挖（≥3000 字）+ 真实案例  
   B. 三篇连载（基础 → 落地 → 复盘）*推荐*  
   C. 快速综述（1500–2000 字）+ “可执行清单”附录  
   D. 对比评测（框架/平台对比 + 选型矩阵）

## 5. 已确认决策（来自对话）
- 用户指令：待决策项全部按模型推荐。
- 已选：
  - 主选题：选题 5（Agent 可观测性 / AgentOps）
  - 形式：三篇连载（基础 → 落地 → 复盘）

## 6. 写作产出（已落盘）
- Part 1/3（中文）：`source/_posts/2026-01-agentops-observability-1.md`
- Part 1/3（英文）：`source/_posts/2026-01-agentops-observability-1-en.md`

## 7. 后续建议（连载规划）
- Part 2/3（落地篇）：埋点与看板的 MVP（Trace/Metric/Log）、回放与脱敏策略、常见坑清单
- Part 3/3（复盘篇）：把 Agent 可观测性接入 SLO/错误预算、安全审计与变更闸门（含复盘模板）

## 8. 2026-01-27 选题阶段补充（下一篇/下一轮）
> 说明：本节用于“选题阶段”补充候选与待决策项；不覆盖第 5 节已确认决策。

### 8.1 现状补充（新增文章）
- MCP（中文）：`source/_posts/2026-01-mcp-agent-interface.md`
- MCP（英文）：`source/_posts/2026-01-mcp-agent-interface-en.md`

### 8.2 候选（建议 6 个，优先承接站内 AI 系列）

#### 8.2.1 候选 1：Agent 可观测性（AgentOps）②：埋点与看板的 MVP（Trace/Metric/Log）
- English: **Agent Observability (AgentOps) Part 2: Instrumentation MVP, Dashboards, and Replay**
- 价值：把 Part 1 的“观测模型”落到可运行的最小方案：怎么埋点、怎么建看板、怎么做回放与脱敏；也为后续 Evals/安全审计打数据底座。
- 提纲：
  1) 埋点清单：哪些 span/metric/log 必须有（最小必需字段）  
  2) 数据管道：采样、脱敏、落库与关联（trace_id / session_id）  
  3) 看板与告警：失败模式 TopN、成本/延迟拆解、工具依赖健康度  
  4) 回放与复盘：从一次 Trace 复现“决策链”，定位根因与回归验证
- 标签：`['#Observability', '#OpenTelemetry', '#AIInfrastructure', '#SRE', '#Tracing']`

#### 8.2.2 候选 2：Agent 可观测性（AgentOps）③：把可观测性接入 SLO/错误预算/安全审计/发布闸门
- English: **Agent Observability (AgentOps) Part 3: SLOs, Error Budgets, Security Audits, and Release Gates**
- 价值：把“看得见”升级为“管得住”：用 SLO/错误预算把质量、成本、风险纳入同一套治理闭环，并形成可执行的发布闸门与复盘模板。
- 提纲：
  1) 定义 SLO：正确性/稳定性/成本/延迟/拒答率的口径与阈值  
  2) 错误预算：触发降级、关停工具、切换模型与回滚策略  
  3) 安全审计：越权调用、敏感数据外泄、注入攻击的可追责证据链  
  4) 发布闸门：变更影响评估、灰度/回滚、复盘模板与组织流程
- 标签：`['#SLO', '#Observability', '#Security', '#AI', '#Practice']`

#### 8.2.3 候选 3：Agent Evals：把 Prompt / Tool / Workflow 纳入 CI 的回归测试
- English: **Agent Evals: Regression Testing for Prompts, Tools, and Workflows**
- 价值：解决“改了 Prompt/策略但线上悄悄变坏”的痛点；与 AgentOps 的 Trace/回放天然互补，形成质量闸门的闭环。
- 提纲：
  1) 测试分层：单步 / 工作流 / 端到端，分别测什么  
  2) 用例来源：线上 Trace 回放、合成数据、人工标注与漂移监测  
  3) 指标体系：正确性、稳定性、成本、延迟、拒答率与鲁棒性  
  4) CI 落地：红线闸门、灰度发布、自动回滚与告警联动
- 标签：`['#AI', '#Testing', '#Observability', '#Automation', '#SLO']`

#### 8.2.4 候选 4：多模型路由与推理 FinOps：Router + Cache + 灰度
- English: **Multi-Model Routing & LLM FinOps: Router, Cache, and Rollouts**
- 价值：把“质量/成本/延迟”当作三角约束，给出可落地的路由、缓存、降级与发布策略；可作为 AI 性能预算系列的续篇。
- 提纲：
  1) 路由策略：规则/Embedding/Router Model/分层升级  
  2) 缓存策略：Prompt Caching vs 语义缓存（命中率与一致性）  
  3) 预算联动：成本上限、延迟 SLO 与自动降级  
  4) 灰度发布：按客群/风险/地域分流与回滚
- 标签：`['#CostOptimization', '#FinOps', '#AIInfrastructure', '#Architecture', '#Performance']`

#### 8.2.5 候选 5：Agent 安全基线：从 Prompt Injection 到 Tool Abuse 的防线
- English: **Securing Agents: From Prompt Injection to Tool Abuse**
- 价值：把“Agent 接工具 = 新攻击面”讲清楚，并给出能抄作业的安全基线与 Checklist；可直接承接 MCP 工具接入的安全落地。
- 提纲：
  1) 威胁模型：提示注入、越权调用、数据外泄、供应链风险  
  2) 防护分层：输入净化、策略引擎、工具权限、沙箱隔离  
  3) 审计与追责：日志、Trace、回放与变更审计  
  4) 组织流程：安全评审 Checklist + 红队演练
- 标签：`['#Security', '#AI', '#Agents', '#Checklist', '#Practice']`

#### 8.2.6 候选 6：RAG 2.0：从向量检索到“结构化知识 + 图谱 + 权限”
- English: **RAG 2.0: Beyond Vectors—Structured Data, Graphs, and Permissions**
- 价值：把 RAG 从“堆向量库”升级为可治理的数据系统：新鲜度、权限、多租户、引用可追溯；可与站内数据库/CDC/检索性能主题串联。
- 提纲：
  1) 混合检索：BM25 + Vector + SQL（以及何时引入图）  
  2) 数据新鲜度：CDC/增量索引/回滚与一致性  
  3) 权限与多租户：行级权限、过滤与审计  
  4) 可信回答：引用、置信度、拒答与可追溯
- 标签：`['#RAG', '#Database', '#Search', '#MultiTenant', '#AI']`

### 8.3 待决策项（下一篇写作入口）
1) 下一篇优先写哪一篇（从“延续性 + 产出效率”角度推荐）：  
   A. 候选 1（AgentOps ②：埋点与看板 MVP）*推荐*  
   B. 候选 3（Agent Evals：回归测试）  
   C. 候选 5（Agent 安全基线）  
   D. 候选 4（多模型路由与 FinOps）

2) 双语产出策略：  
   A. 同步中文 + 英文（同一周内）*推荐*  
   B. 先中文后英文（间隔 1–2 周）  
   C. 仅中文  
   D. 仅英文

### 8.4 已确认决策（2026-01-27）
- ✅ 下一篇主选题：候选 6（RAG 2.0：结构化知识 + 图谱 + 权限）
- ✅ 双语策略：A（同步中文 + 英文）
- ✅ 已进入写作阶段并落盘：
  - 中文：`source/_posts/2026-01-rag-2-0-governable-rag.md`
  - 英文：`source/_posts/2026-01-rag-2-0-governable-rag-en.md`

## 9. 2026-01-29 选题阶段补充（下一篇/下一轮）
> 说明：本节用于“选题阶段”补充候选与待决策项；不覆盖既有历史决策与已落盘文章。

### 9.1 现状补充（站内 AI 系列已覆盖）
- AgentOps ①（已落盘）：
  - 中文：`source/_posts/2026-01-agentops-observability-1.md`
  - 英文：`source/_posts/2026-01-agentops-observability-1-en.md`
- MCP（已落盘）：
  - 中文：`source/_posts/2026-01-mcp-agent-interface.md`
  - 英文：`source/_posts/2026-01-mcp-agent-interface-en.md`
- RAG 2.0（已落盘）：
  - 中文：`source/_posts/2026-01-rag-2-0-governable-rag.md`
  - 英文：`source/_posts/2026-01-rag-2-0-governable-rag-en.md`

### 9.2 候选（建议 6 个，优先补齐“质量闸门/网关治理/可靠性/安全”闭环）

#### 9.2.1 候选 1：Agent Evals：把 Prompt / Tool / RAG 变更纳入 CI 的回归与漂移监测
- English: **Agent Evals in CI: Regression & Drift Testing for Prompts, Tools, and RAG**
- 价值：把“可观测”升级为“可验证”：每次改 Prompt、路由、检索、工具策略，都能用可回放用例与红线指标在 CI 里提前拦截回归；与 AgentOps/RAG 2.0 形成质量闭环。
- 提纲：
  1) 测试分层：单步 / 工作流 / 端到端；离线 vs 线上 Shadow/Canary  
  2) 用例来源：线上 Trace 回放、黄金集（golden set）、合成数据与人工标注  
  3) 指标体系：正确性、groundedness（引用支撑）、安全、成本、延迟与波动性  
  4) CI 落地：红线闸门、灰度发布、自动回滚与告警联动
- 标签：`['#AI', '#Testing', '#Observability', '#Automation', '#SLO']`

#### 9.2.2 候选 2：AI Gateway：把 LLM 调用从 SDK 升级为“可治理的网关层”（鉴权/限流/缓存/审计）
- English: **AI Gateway: Turning LLM Calls into a Governed Gateway Layer**
- 价值：当模型/供应商/团队变多后，问题不再是“怎么调用”，而是“怎么治理”：统一鉴权、密钥托管、限流、预算、重试、缓存与审计，让 LLM 能像 API 一样被平台化运营。
- 提纲：
  1) 为什么需要网关：多模型路由、密钥治理、成本预算、SLO 与弹性  
  2) 核心能力：鉴权/配额、限流、重试/熔断、缓存、降级与多租户隔离  
  3) 可观测与审计：Trace/Log/指标、PII 脱敏、请求回放与合规留痕  
  4) 形态选型：Sidecar vs 中央网关；灰度、HA 与故障演练
- 标签：`['#AIInfrastructure', '#Architecture', '#Security', '#Observability', '#FinOps']`

#### 9.2.3 候选 3：结构化输出与契约：让 LLM 生成的 JSON 可验证、可回滚、可演进
- English: **Structured Outputs & Contracts: Validating, Versioning, and Evolving LLM JSON**
- 价值：把“生成文本”升级为“生成可运行的结构化数据”：用 Schema/契约治理把不可控输出变成可验证输入，解决生产常见的解析失败、字段漂移与兼容性问题。
- 提纲：
  1) 失效模式：缺字段/多字段、类型错误、枚举漂移、国际化与边界值  
  2) 契约设计：JSON Schema/OpenAPI；版本演进与向后兼容策略  
  3) 验证与修复：校验器 + 自动修复回路（re-ask / self-heal / fallback）  
  4) 工程落地：幂等、重试、回滚与灰度（避免“结构化输出”变成线上炸点）
- 标签：`['#AI', '#Reliability', '#Schema', '#Engineering', '#Tooling']`

#### 9.2.4 候选 4：Prompt Injection 实战：RAG 与 Agent 的“数据/工具”双向防线（含可抄 Checklist）
- English: **Prompt Injection in Practice: Defenses for RAG and Tool-Using Agents**
- 价值：把“Agent 接工具 = 新攻击面”讲清楚：不仅要防输出被带偏，更要防检索内容与工具调用被越权操纵；适合承接 MCP/RAG 的落地风险与治理。
- 提纲：
  1) 攻击面：直接/间接注入、数据投毒、越权调用与供应链风险  
  2) RAG 防线：来源白名单、内容净化、引用与溯源、权限过滤前置  
  3) Tool 防线：最小权限、能力（capability）模型、审批/双人复核与沙箱  
  4) 监测与响应：检测信号、审计证据链、红队演练与修复流程
- 标签：`['#Security', '#AI', '#Agents', '#RAG', '#Checklist']`

#### 9.2.5 候选 5：Context Engineering：上下文预算、记忆与摘要的工程化（成本/延迟/正确性三角）
- English: **Context Engineering: Budgets, Memory, and Summarization in Production**
- 价值：把“上下文窗口”当成可运营的资源：如何做截断、摘要、记忆检索与隐私脱敏，才能在不爆成本的前提下保证回答质量与稳定性。
- 提纲：
  1) 上下文预算：token 经济学、延迟来源、截断/压缩策略与失败模式  
  2) 记忆模式：工作记忆/情景记忆/长期记忆；检索 vs 摘要的取舍  
  3) 隐私与合规：保留策略、删除权、PII 脱敏与可审计回放  
  4) 评估方法：召回率/可用率/成本/延迟的联合指标与 A/B 验证
- 标签：`['#AI', '#Performance', '#CostOptimization', '#Architecture', '#Privacy']`

#### 9.2.6 候选 6：边缘/端侧 LLM：什么时候该上设备、什么时候该上云（隐私、延迟与成本）
- English: **Edge & On-Device LLMs: Choosing Between Device and Cloud**
- 价值：承接你已有的 Edge/Serverless 主题：在隐私、离线可用、低延迟与成本之间做“可解释的选型”，并给出混合架构的落地路线。
- 提纲：
  1) 选型矩阵：隐私、延迟、带宽、离线、个性化与运维复杂度  
  2) 运行形态：边缘函数、端侧 Runtime、模型分发与增量更新  
  3) 混合架构：端侧预处理 + 云端推理；端侧检索 + 云端生成  
  4) 可运营性：版本治理、监控、回滚与攻击面（模型/提示/数据）
- 标签：`['#Edge', '#Privacy', '#AIInfrastructure', '#Performance', '#Architecture']`

### 9.3 待决策项（下一篇写作入口）
1) 下一篇优先写哪一篇（从“延续性 + 产出效率”角度推荐）：  
   A. 候选 1（Agent Evals：CI 回归与漂移监测）*推荐*  
   B. 候选 2（AI Gateway：可治理的网关层）  
   C. 候选 4（Prompt Injection 实战：数据/工具双向防线）  
   D. 候选 3（结构化输出与契约：可验证 JSON）

2) 双语产出策略：  
   A. 同步中文 + 英文（同一周内）*推荐*  
   B. 先中文后英文（间隔 1–2 周）  
   C. 仅中文  
   D. 仅英文

### 9.4 已确认决策（2026-01-29）
- ✅ 下一篇主选题：候选 2（AI Gateway：把 LLM 调用升级为“可治理的网关层”）
- ✅ 双语策略：A（同步中文 + 英文，同一周内）
- ✅ 写作阶段已完成（已落盘）：
  - 中文：`source/_posts/2026-01-ai-gateway-governance.md`
  - 英文：`source/_posts/2026-01-ai-gateway-governance-en.md`
